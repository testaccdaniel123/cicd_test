name: Benchmark

on:
  workflow_dispatch:

jobs:
  prepare-benchmark:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      configurations: ${{ steps.prepare-config.outputs.configurations }}
    env:
      GENERAL_PATHS: "./.github/workflows ./.github/pattern.json ./Tools/Python ./Tools/sysbench_script.sh"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Read and generate matrix
        id: set-matrix
        run: |
          CONFIG_FILE=".github/pattern.json"
          matrix=$(jq -c 'keys' $CONFIG_FILE)
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

      - name: Prepare configurations for all test types
        id: prepare-config
        run: |
          CONFIG_FILE=".github/pattern.json"
          RESULTS=()
          ALL_ARTIFACTS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" "https://api.github.com/repos/${{ github.repository }}/actions/artifacts")
          
          for TEST_TYPE in $(jq -r 'keys[]' $CONFIG_FILE); do
            SCRIPTS=$(jq -r --arg test "$TEST_TYPE" '.[$test].scripts | @json' "$CONFIG_FILE")
            VAR=$(jq -c --arg test "$TEST_TYPE" '.[$test].var // {}' "$CONFIG_FILE")
            if [[ $(jq -r --arg test "$TEST_TYPE" '.[$test].scripts | keys_unsorted | .[0]' "$CONFIG_FILE") =~ /Projects\/(.*)\/Scripts/ ]]; then
              OUTPUT_DIR="Output/${BASH_REMATCH[1]}/${TEST_TYPE}"
            fi
            HASH=$(echo "$SCRIPTS" | jq -r 'keys_unsorted[]' | xargs -I {} find {} -type f -print0 | sort -z | xargs -0 sha256sum | sha256sum | awk '{print $1}')
            LAST_COMMIT=$(git rev-parse HEAD || git rev-parse origin/main)
            GENERAL_HASH=$(git ls-tree -r $LAST_COMMIT -- $GENERAL_PATHS | awk '{print $3}' | xargs -I {} git show {} | sha256sum | awk '{print $1}')
          
            ARTIFACT_NAME="${TEST_TYPE}-${HASH}-${GENERAL_HASH}"
            SHOULD_RUN=$(echo "$ALL_ARTIFACTS" | jq -e --arg name "$ARTIFACT_NAME" '.artifacts[] | select(.name == $name) | .id' > /dev/null && echo false || echo true)
            ENVS=$(jq -r --arg test "$TEST_TYPE" '.[$test].scripts | to_entries | map(if .value.db then .value.db else "mysql" end) | unique | join(",")' "$CONFIG_FILE")
          
            # Creation of the JSON result
            RESULT=$(jq -n \
            --arg test_type "$TEST_TYPE" \
            --arg scripts "$SCRIPTS" \
            --arg var "$VAR" \
            --arg output_dir "$OUTPUT_DIR" \
            --arg artifact_name "$ARTIFACT_NAME" \
            --arg should_run "$SHOULD_RUN" \
            --arg envs "$ENVS" \
            '{test_type: $test_type, scripts: $scripts, var: $var, output_dir: $output_dir, artifact_name: $artifact_name, should_run: $should_run, envs: $envs}')
          
            RESULTS+=("$RESULT")
          done
          CONFIGURATIONS=$(printf '%s\n' "${RESULTS[@]}" | jq -s '.' | jq -c .)
          echo "configurations=$CONFIGURATIONS" >> $GITHUB_OUTPUT

  run-tests:
    needs: prepare-benchmark
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: ${{ fromJson(needs.prepare-benchmark.outputs.matrix) }}
    env:
      TIME: 8
      THREADS: 1
      EVENTS: 0
      REPORT_INTERVAL: 1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Extract and save values to GitHub environment
        run: |
          CONFIG=$(echo '${{ needs.prepare-benchmark.outputs.configurations }}' | jq -c --arg test_type "${{ matrix.test-type }}" '.[] | select(.test_type == $test_type)')
          for key in $(echo $CONFIG | jq -r 'keys[]'); do
            value=$(echo $CONFIG | jq -r ".${key}")
            echo "${key}=${value}" >> $GITHUB_ENV
          done

      - name: Cache pip dependencies
        if: env.should_run == 'true'
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Install dependencies
        if: env.should_run == 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y sysbench
          python -m pip install --upgrade pip
          pip install pandas matplotlib

      - name: Start PostgreSQL container
        if: env.should_run == 'true' && contains(env.envs, 'postgres')
        run: |
          eval $(jq -r --arg env "postgres" '.[$env] | to_entries | .[] | "export " + .key + "=" + (.value | @sh)' "./envs.json")
          docker run --name postgres-${{ env.test_type }} -d \
            -e POSTGRES_PASSWORD=$DB_PASS \
            -e POSTGRES_DB=$DB_NAME \
            -p $DB_PORT:$DB_PORT postgres:15
          
          echo "Waiting for PostgreSQL..."
          until docker exec postgres-${{ env.test_type }} pg_isready --host=$DB_HOST --port=$DB_PORT --username=$DB_USER; do sleep 1; done
          echo "PostgreSQL is ready!"

      - name: Start MySQL container
        if: env.should_run == 'true' && contains(env.envs, 'mysql')
        run: |
          eval $(jq -r --arg env "mysql" '.[$env] | to_entries | .[] | "export " + .key + "=" + (.value | @sh)' "./envs.json")
          docker run --name mysql-${{ env.test_type }} -d \
            -e MYSQL_ROOT_PASSWORD=$DB_PASS \
            -e MYSQL_DATABASE=$DB_NAME \
            -p $DB_PORT:$DB_PORT mysql:8.0
          
          echo "Waiting for MySQL..."
          until docker exec mysql-${{ env.test_type }} mysqladmin --user=$DB_USER --password=$DB_PASS --host=$DB_HOST --port=$DB_PORT ping --silent; do sleep 1; done
          echo "MySQL is ready!"

      - name: Run sysbench script
        if: env.should_run == 'true'
        run: |
          chmod +x Tools/sysbench_script.sh

          Tools/sysbench_script.sh \
            -out "${{ env.output_dir }}" \
            -var '${{ env.var }}' \
            -scripts '${{ env.scripts }}'

      - name: Stop MySQL and PostgreSQL containers
        if: env.should_run == 'true'
        run: |
          docker ps -q -f name=mysql-${{ env.test_type }} | xargs -r docker stop | xargs -r docker rm
          docker ps -q -f name=postgres-${{ env.test_type }} | xargs -r docker stop | xargs -r docker rm

      - name: Upload individual outputs
        if: env.should_run == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.artifact_name }}
          path: ${{ env.output_dir }}

  upload-combined-output:
    needs: [ prepare-benchmark, run-tests ]
    runs-on: ubuntu-latest
    steps:
      - name: Loop through configurations and download artifacts
        run: |
          CONFIGS='${{ needs.prepare-benchmark.outputs.configurations }}'

          ALL_ARTIFACTS=$(curl -s -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" "https://api.github.com/repos/${{ github.repository }}/actions/artifacts")
          
          echo "$CONFIGS" | jq -c '.[]' | while read -r test_case; do
            artifact_name=$(echo "$test_case" | jq -r '.artifact_name')
            output_dir=$(echo "$test_case" | jq -r '.output_dir')
            artifact_id=$(echo "$ALL_ARTIFACTS" | jq -r --arg name "$artifact_name" '.artifacts[] | select(.name == $name) | .id')
          
            echo "Downloading for artifact $artifact_name with ID $artifact_id"
            curl -L -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/$artifact_id/zip" \
              -o artifact.zip
            mkdir -p "$output_dir"
            unzip -q artifact.zip -d "$output_dir"
            rm artifact.zip
          done

      - name: Upload combined outputs as an artifact
        uses: actions/upload-artifact@v4
        with:
          name: combined-output
          path: Output